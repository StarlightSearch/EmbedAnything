{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fH4EwHBUQ1Ve"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install lancedb embed-anything-gpu datasets huggingface_hub smolagents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBsHxyZ0UF_z",
        "outputId": "50c47162-175f-46b7-c353-875ffe82d685"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "urls = [\n",
        "    \"https://content.dgft.gov.in/Website/CIEP.pdf\",\n",
        "    \"https://content.dgft.gov.in/Website/GAE.pdf\",\n",
        "    \"https://content.dgft.gov.in/Website/HTE.pdf\",\n",
        "]\n",
        "\n",
        "med_url = [\"https://www.biorxiv.org/content/10.1101/2025.01.23.634433v1.full.pdf\"]\n",
        "\n",
        "def download_files(urls, folder_name=\"downloaded_docs\"):\n",
        "    \"\"\"Downloads files from a list of URLs to a specified folder.\"\"\"\n",
        "\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "            parsed_url = urlparse(url)\n",
        "            filename = os.path.basename(parsed_url.path)\n",
        "            filepath = os.path.join(folder_name, filename)\n",
        "\n",
        "            with open(filepath, 'wb') as file:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    file.write(chunk)\n",
        "\n",
        "            print(f\"Downloaded {filename} to {folder_name}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading {url}: {e}\")\n",
        "\n",
        "\n",
        "def med_files(urls, folder_name=\"medical_docs\"):\n",
        "    \"\"\"Downloads files from a list of URLs to a specified folder.\"\"\"\n",
        "\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "\n",
        "    for url in med_url:\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "            parsed_url = urlparse(url)\n",
        "            filename = os.path.basename(parsed_url.path)\n",
        "            filepath = os.path.join(folder_name, filename)\n",
        "\n",
        "            with open(filepath, 'wb') as file:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    file.write(chunk)\n",
        "\n",
        "            print(f\"Downloaded {filename} to {folder_name}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading {url}: {e}\")\n",
        "\n",
        "download_files(urls)\n",
        "med_files(med_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def download_files_generic(urls, folder_name, chunk_size=8192):\n",
        "    \"\"\"\n",
        "    Downloads files from a list of URLs to a specified folder.\n",
        "    \n",
        "    Args:\n",
        "        urls (list): List of URLs to download files from\n",
        "        folder_name (str): Name of the folder to save files to\n",
        "        chunk_size (int, optional): Size of chunks to download. Defaults to 8192\n",
        "        \n",
        "    Returns:\n",
        "        list: List of tuples containing (filename, success_status, error_message if any)\n",
        "    \"\"\"\n",
        "    if not isinstance(urls, (list, tuple)):\n",
        "        raise ValueError(\"URLs must be provided as a list or tuple\")\n",
        "        \n",
        "    if not folder_name:\n",
        "        raise ValueError(\"Folder name must be provided\")\n",
        "        \n",
        "    # Create results list to track downloads\n",
        "    results = []\n",
        "    \n",
        "    # Create folder if it doesn't exist\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "    \n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            parsed_url = urlparse(url)\n",
        "            filename = os.path.basename(parsed_url.path)\n",
        "            \n",
        "            # Handle empty filenames\n",
        "            if not filename:\n",
        "                filename = f\"downloaded_file_{len(results)}\"\n",
        "                \n",
        "            filepath = os.path.join(folder_name, filename)\n",
        "            \n",
        "            with open(filepath, 'wb') as file:\n",
        "                for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                    file.write(chunk)\n",
        "                    \n",
        "            print(f\"Downloaded {filename} to {folder_name}\")\n",
        "            results.append((filename, True, None))\n",
        "            \n",
        "        except requests.exceptions.RequestException as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"Error downloading {url}: {error_msg}\")\n",
        "            results.append((url, False, error_msg))\n",
        "            \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vkWbKldQX6CB"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from smolagents import Tool\n",
        "\n",
        "import lancedb\n",
        "import embed_anything\n",
        "from embed_anything import EmbeddingModel, WhichModel, ONNXModel\n",
        "from uuid import uuid4\n",
        "\n",
        "\n",
        "class RetrieverTool(Tool):\n",
        "    name = \"retriever\"\n",
        "    description = \"Uses semantic search to retrieve policies about india that could be most relevant to answer your query.\"\n",
        "    inputs = {\n",
        "        \"query\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
        "        }\n",
        "    }\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def __init__(self, directory, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = EmbeddingModel.from_pretrained_onnx(WhichModel.Bert, ONNXModel.AllMiniLML6V2Q)\n",
        "        self.connection = lancedb.connect(\"tmp/general\")\n",
        "        if \"docs\" in self.connection.table_names():\n",
        "            self.table = self.connection.open_table(\"docs\")\n",
        "        else:\n",
        "            self.embeddings = embed_anything.embed_directory(directory, embedder = self.model)\n",
        "            docs = []\n",
        "            for e in self.embeddings:\n",
        "                docs.append({\n",
        "                    \"vector\": e.embedding,\n",
        "                    \"text\": e.text,\n",
        "                    \"id\": str(uuid4())\n",
        "                })\n",
        "            self.table = self.connection.create_table(\"docs\", docs)\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        assert isinstance(query, str), \"Your search query must be a string\"\n",
        "\n",
        "        query_vec = embed_anything.embed_query([query], embedder = self.model)[0].embedding\n",
        "        docs = self.table.search(query_vec).limit(5).to_pandas()[\"text\"]\n",
        "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "            [f\"\\n\\n===== Document {str(i)} =====\\n\" + doc for i, doc in enumerate(docs)]\n",
        "        )\n",
        "\n",
        "class MedicalRetrieverTool(Tool):\n",
        "    name = \"medical_retriever\"\n",
        "    description = \"Uses semantic search to retrieve medicine related documennts most relevant to answer your query. Use this when the query is rlated to medicine or medical science or physiotherapy or psychology. \"\n",
        "    inputs = {\n",
        "        \"query\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
        "        }\n",
        "    }\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def __init__(self, directory, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model =EmbeddingModel.from_pretrained_hf(WhichModel.Bert, model_id='NeuML/pubmedbert-base-embeddings')\n",
        "        self.connection = lancedb.connect(\"tmp/medical\")\n",
        "        if \"docs\" in self.connection.table_names():\n",
        "            self.table = self.connection.open_table(\"docs\")\n",
        "        else:\n",
        "            self.embeddings = embed_anything.embed_directory(directory, embedder = self.model)\n",
        "            docs = []\n",
        "            for e in self.embeddings:\n",
        "                docs.append({\n",
        "                    \"vector\": e.embedding,\n",
        "                    \"text\": e.text,\n",
        "                    \"id\": str(uuid4())\n",
        "                })\n",
        "            self.table = self.connection.create_table(\"docs\", docs)\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        assert isinstance(query, str), \"Your search query must be a string\"\n",
        "\n",
        "        query_vec = embed_anything.embed_query([query], embedder = self.model)[0].embedding\n",
        "        docs = self.table.search(query_vec).limit(5).to_pandas()[\"text\"]\n",
        "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "            [f\"\\n\\n===== Document {str(i)} =====\\n\" + doc for i, doc in enumerate(docs)]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SWrVHA_DDQHf",
        "outputId": "aa8ef099-7aa8-4760-eb85-39c5ea340420"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from smolagents import Tool\n",
        "\n",
        "import lancedb\n",
        "import embed_anything\n",
        "from embed_anything import EmbeddingModel, WhichModel, ONNXModel\n",
        "from uuid import uuid4\n",
        "\n",
        "from smolagents import CodeAgent, OpenAIServerModel, TransformersModel, DuckDuckGoSearchTool\n",
        "from google.colab import userdata\n",
        "api_key = os.environ.get('OPENAI_API_KEY') # Get the key from environment variables\n",
        "retriever_tool = RetrieverTool(\"downloaded_docs\")\n",
        "medical_tool = MedicalRetrieverTool(\"medical_docs\")\n",
        "# medical_tool = RetrieverTool(\"downloaded_docs\")\n",
        "agent = CodeAgent(\n",
        "    tools=[retriever_tool, medical_tool],\n",
        "    model=OpenAIServerModel(model_id = \"gpt-4o-mini\", api_base = \"https://api.openai.com/v1/\", api_key = api_key),\n",
        "    verbosity_level=2,\n",
        ")\n",
        "\n",
        "agent_output = agent.run(\"What are the different policies for indian manufacturing and what are the medical risks of radiotherapy?\")\n",
        "\n",
        "print(\"Final output:\")\n",
        "print(agent_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPLaB9fcuPXb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
